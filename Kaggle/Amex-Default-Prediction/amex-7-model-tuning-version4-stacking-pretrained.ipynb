{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55052c18",
   "metadata": {
    "papermill": {
     "duration": 0.007048,
     "end_time": "2022-08-09T13:06:20.487291",
     "exception": false,
     "start_time": "2022-08-09T13:06:20.480243",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Amex - Model Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59f4f6df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T13:06:20.501726Z",
     "iopub.status.busy": "2022-08-09T13:06:20.501145Z",
     "iopub.status.idle": "2022-08-09T13:06:22.820474Z",
     "shell.execute_reply": "2022-08-09T13:06:22.819508Z"
    },
    "papermill": {
     "duration": 2.329846,
     "end_time": "2022-08-09T13:06:22.823186",
     "exception": false,
     "start_time": "2022-08-09T13:06:20.493340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cd0d5f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T13:06:22.839266Z",
     "iopub.status.busy": "2022-08-09T13:06:22.838580Z",
     "iopub.status.idle": "2022-08-09T13:06:49.491829Z",
     "shell.execute_reply": "2022-08-09T13:06:49.490659Z"
    },
    "papermill": {
     "duration": 26.664001,
     "end_time": "2022-08-09T13:06:49.494673",
     "exception": false,
     "start_time": "2022-08-09T13:06:22.830672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_pickle('../input/amexshycombinedfeatures/train.pkl')\n",
    "trainY = pd.read_pickle('../input/amexshycombinedfeatures/trainY.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82b6461d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T13:06:49.508430Z",
     "iopub.status.busy": "2022-08-09T13:06:49.507683Z",
     "iopub.status.idle": "2022-08-09T13:06:56.479259Z",
     "shell.execute_reply": "2022-08-09T13:06:56.477846Z"
    },
    "papermill": {
     "duration": 6.980893,
     "end_time": "2022-08-09T13:06:56.481680",
     "exception": false,
     "start_time": "2022-08-09T13:06:49.500787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns = [f'f_{_}' for _ in range(0,train.shape[1])]\n",
    "for i in train.columns:\n",
    "    if train[i].dtypes == 'object':\n",
    "        train[i]=train[i].apply(lambda x: hash(str(x))%997)\n",
    "import pickle\n",
    "with open('../input/amexshycombinedfeatures/selected1.pickle', 'rb') as file:    \n",
    "    selected1 = pickle.load(file)    \n",
    "with open('../input/amexshycombinedfeatures/selected2.pickle', 'rb') as file:    \n",
    "    selected2 = pickle.load(file)    \n",
    "with open('../input/amexshycombinedfeatures/selected3.pickle', 'rb') as file:    \n",
    "    selected3 = pickle.load(file)    \n",
    "columns = []\n",
    "for i,j,k,l in zip(train.columns,selected1,selected2,selected3):\n",
    "    if j == k == l == True:\n",
    "        columns.append(i)\n",
    "train = train[columns]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2838f6c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T13:06:56.497279Z",
     "iopub.status.busy": "2022-08-09T13:06:56.496829Z",
     "iopub.status.idle": "2022-08-09T13:06:56.517875Z",
     "shell.execute_reply": "2022-08-09T13:06:56.516757Z"
    },
    "papermill": {
     "duration": 0.031711,
     "end_time": "2022-08-09T13:06:56.520319",
     "exception": false,
     "start_time": "2022-08-09T13:06:56.488608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model robustness indicator\n",
    "def calc_vdr(pred, actual, vdr_cutoff = 0.2):\n",
    "    # Function to calculate VDR at a given cutoff\n",
    "\n",
    "    df_vdr_train = pd.DataFrame(zip(pred), columns = ['predicted_proba'])\n",
    "    df_vdr_train['actual'] = np.array(actual)\n",
    "    df_vdr_train = df_vdr_train.sort_values(by = 'predicted_proba', ascending = False)\n",
    "    num_bad = df_vdr_train['actual'].sum()\n",
    "    top_20_pct = int(len(df_vdr_train['actual'])*vdr_cutoff)\n",
    "    vdr = df_vdr_train.head(top_20_pct)['actual'].sum()/num_bad\n",
    "    return vdr\n",
    "\n",
    "# evaluation matrix\n",
    "\n",
    "# 4% cutoff measures the true positive rate of the 4% data\n",
    "# positives are given 20x weights\n",
    "# cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "# the code above indicates that if we successfully detect more positive cases, we will get less cut_samples\n",
    "# since negative samples have weight of 1, we should have more samples to let cut_vals reach threshold\n",
    "# the top four value equals to the ture positive numbers in cut_vals samples/the number of all true positive samples\n",
    "# therefore, our models should be more sensitive to true positive cases and have a larger true positive rate\n",
    "\n",
    "# gini = 2(ROC-0.5)\n",
    "\n",
    "def amex_metric_mod(y_true, y_pred):\n",
    "\n",
    "    labels     = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels     = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights    = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "    print(f'Top four({len(cut_vals[:,0])} total cases) has {top_four*100}% positives cases being predicted')    \n",
    "\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels         = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels         = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight         = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random  = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos      = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz        = cum_pos_found / total_pos\n",
    "        gini[i]        = np.sum((lorentz - weight_random) * weight)\n",
    "    print(f'Gini value is {gini[1]/gini[0]}')\n",
    "    \n",
    "    \n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)\n",
    "\n",
    "# matplotlib\n",
    "def plot_auc(y_test, pred_prob1,pred_prob2,modelname,modelname2):\n",
    "    from sklearn.metrics import roc_curve\n",
    "\n",
    "    # roc curve for models\n",
    "    fpr1, tpr1, thresh1 = roc_curve(y_test, pred_prob1, pos_label=1)\n",
    "    fpr2, tpr2, thresh2 = roc_curve(y_test, pred_prob2, pos_label=1)\n",
    "\n",
    "\n",
    "    # roc curve for tpr = fpr \n",
    "    random_probs = [0 for i in range(len(y_test))]\n",
    "    p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)\n",
    "\n",
    "    plt.style.use('seaborn')\n",
    "\n",
    "    # plot roc curves\n",
    "    plt.plot(fpr1, tpr1, linestyle='--',color='orange', label=modelname)\n",
    "    plt.plot(fpr2, tpr2, linestyle='--',color='green', label=modelname2)\n",
    "    plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
    "    # title\n",
    "    plt.title('ROC curve')\n",
    "    # x label\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    # y label\n",
    "    plt.ylabel('True Positive rate')\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "#     plt.savefig('ROC',dpi=)\n",
    "    plt.show()\n",
    "    \n",
    "def evaluation(gbm, train_x, valid_x, sig):\n",
    "    # lightgbm single model evaluation in cv\n",
    "    # predict the valid dataset in cv\n",
    "    if sig == 'class':\n",
    "        train_score_lgm = gbm.predict_proba(train_x)[:,1]\n",
    "        valid_score_lgm = gbm.predict_proba(valid_x)[:,1]\n",
    "    elif sig == 'reg':\n",
    "        train_score_lgm = gbm.predict(train_x)\n",
    "        valid_score_lgm = gbm.predict(valid_x)\n",
    "    # get roc score\n",
    "    roc_auc_train = sklearn.metrics.roc_auc_score(train_y, train_score_lgm)\n",
    "    roc_auc_valid = sklearn.metrics.roc_auc_score(valid_y, valid_score_lgm)\n",
    "    # get the provided evaluation metrics of Gini and D score\n",
    "    score_train = amex_metric_mod(train_y, train_score_lgm)\n",
    "    score_valid = amex_metric_mod(valid_y, valid_score_lgm)\n",
    "\n",
    "    print('LGB - METRICS')\n",
    "    print('LGB: Train_score: {:.4f} valid_score: {:.4f}'.format(roc_auc_train , roc_auc_valid))\n",
    "    print(f'LGB: train_vdr score: {calc_vdr(train_score_lgm,actual=train_y)}')\n",
    "    print(f'LGB: valid_vdr score: {calc_vdr(valid_score_lgm,actual=valid_y)}')\n",
    "    #joblib.dump(gbm,'./model_shy/lgm'+str(round(sklearn.metrics.roc_auc_score(valid_y, valid_score_lgm),5)).replace('0.','')+'.model')\n",
    "    print('LGB: Train_score: {:.4f} valid_score: {:.4f}'.format(score_train, score_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f455e4a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T13:06:56.534339Z",
     "iopub.status.busy": "2022-08-09T13:06:56.533671Z",
     "iopub.status.idle": "2022-08-09T13:07:13.308718Z",
     "shell.execute_reply": "2022-08-09T13:07:13.307493Z"
    },
    "papermill": {
     "duration": 16.785137,
     "end_time": "2022-08-09T13:07:13.311559",
     "exception": false,
     "start_time": "2022-08-09T13:06:56.526422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../input/modelspackages/models_lgb_120_004_800_200_04_03.pickle','rb') as file:\n",
    "    models1 = pickle.load(file)\n",
    "with open('../input/modelspackages/models_lgb_120_004_800_200_04_04.pickle','rb') as file:\n",
    "    models2 = pickle.load(file)\n",
    "with open('../input/modelspackages/models_lgb_140_003_800_200_06_03.pickle','rb') as file:\n",
    "    models3 = pickle.load(file)\n",
    "with open('../input/modelspackages/models_xgbc_200_01_06_5_03.pickle','rb') as file:\n",
    "    models4 = pickle.load(file)\n",
    "with open('../input/modelspackages/models_xgbr_300_005_03_5_02.pickle','rb') as file:\n",
    "    models5 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b2e0745",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T13:07:13.328543Z",
     "iopub.status.busy": "2022-08-09T13:07:13.328152Z",
     "iopub.status.idle": "2022-08-09T13:21:23.918536Z",
     "shell.execute_reply": "2022-08-09T13:21:23.917339Z"
    },
    "papermill": {
     "duration": 850.6017,
     "end_time": "2022-08-09T13:21:23.922072",
     "exception": false,
     "start_time": "2022-08-09T13:07:13.320372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0 1\n",
      "0 2\n",
      "0 3\n",
      "0 4\n",
      "1 0\n",
      "1 1\n",
      "1 2\n",
      "1 3\n",
      "1 4\n",
      "2 0\n",
      "2 1\n",
      "2 2\n",
      "2 3\n",
      "2 4\n",
      "3 0\n",
      "3 1\n",
      "3 2\n",
      "3 3\n",
      "3 4\n",
      "4 0\n",
      "4 1\n",
      "4 2\n",
      "4 3\n",
      "4 4\n",
      "5 0\n",
      "5 1\n",
      "5 2\n",
      "5 3\n",
      "5 4\n"
     ]
    }
   ],
   "source": [
    "modelNum = [2022,725,233,514,2333,0]\n",
    "models = []\n",
    "newTrainDF = pd.DataFrame()\n",
    "\n",
    "for idx,_ in enumerate(modelNum):\n",
    "    folds = StratifiedKFold(n_splits= 5, shuffle=True, random_state=_)\n",
    "    list_ = []\n",
    "    list_2 = []\n",
    "    list_3 = []\n",
    "    list_4 = []\n",
    "    list_5 = []\n",
    "    y_ = []\n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train, trainY)):\n",
    "        train_x, train_y = train.iloc[train_idx], trainY.iloc[train_idx]\n",
    "        valid_x, valid_y = train.iloc[valid_idx], trainY.iloc[valid_idx]\n",
    "        \n",
    "        gbm2 = models1[idx*5 + n_fold][0]\n",
    "        gbm3 = models2[idx*5 + n_fold][0]\n",
    "        gbm = models3[idx*5 + n_fold][0]\n",
    "        \n",
    "        list_+= list(gbm.predict_proba(valid_x)[:,1])\n",
    "        list_2+= list(gbm2.predict_proba(valid_x)[:,1])\n",
    "        list_3+= list(gbm3.predict_proba(valid_x)[:,1])\n",
    "        \n",
    "        train_x = train_x.replace([np.inf,-np.inf],0)\n",
    "        train_x.fillna(0,inplace=True)\n",
    "        valid_x = valid_x.replace([np.inf,-np.inf],0)\n",
    "        valid_x.fillna(0,inplace=True)\n",
    "        \n",
    "        xgb1 = models4[idx*5 + n_fold][0]\n",
    "        xgb2 = models5[idx*5 + n_fold][0]\n",
    "        list_4+= list(xgb1.predict_proba(valid_x)[:,1])\n",
    "        list_5+= list(xgb2.predict(valid_x))\n",
    "        y_ += list(valid_y)\n",
    "        print(idx,n_fold)\n",
    "        \n",
    "        \n",
    "        del train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()  \n",
    "    newTrainDF[f'{_}_pred'] = list_\n",
    "    newTrainDF[f'{_}_pred2'] = list_2\n",
    "    newTrainDF[f'{_}_pred3'] = list_3\n",
    "    newTrainDF[f'{_}_pred4'] = list_4\n",
    "    newTrainDF[f'{_}_pred5'] = list_5\n",
    "    gc.collect()\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a57efb14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T13:21:23.941625Z",
     "iopub.status.busy": "2022-08-09T13:21:23.940501Z",
     "iopub.status.idle": "2022-08-09T13:21:24.091161Z",
     "shell.execute_reply": "2022-08-09T13:21:24.090015Z"
    },
    "papermill": {
     "duration": 0.163439,
     "end_time": "2022-08-09T13:21:24.093789",
     "exception": false,
     "start_time": "2022-08-09T13:21:23.930350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2022_pred</th>\n",
       "      <th>2022_pred2</th>\n",
       "      <th>2022_pred3</th>\n",
       "      <th>2022_pred4</th>\n",
       "      <th>2022_pred5</th>\n",
       "      <th>725_pred</th>\n",
       "      <th>725_pred2</th>\n",
       "      <th>725_pred3</th>\n",
       "      <th>725_pred4</th>\n",
       "      <th>725_pred5</th>\n",
       "      <th>...</th>\n",
       "      <th>2333_pred</th>\n",
       "      <th>2333_pred2</th>\n",
       "      <th>2333_pred3</th>\n",
       "      <th>2333_pred4</th>\n",
       "      <th>2333_pred5</th>\n",
       "      <th>0_pred</th>\n",
       "      <th>0_pred2</th>\n",
       "      <th>0_pred3</th>\n",
       "      <th>0_pred4</th>\n",
       "      <th>0_pred5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001478</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>0.002893</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.006012</td>\n",
       "      <td>0.007132</td>\n",
       "      <td>0.010058</td>\n",
       "      <td>0.006341</td>\n",
       "      <td>0.011910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001535</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>0.002221</td>\n",
       "      <td>0.003336</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.730659</td>\n",
       "      <td>0.706918</td>\n",
       "      <td>0.843714</td>\n",
       "      <td>0.640688</td>\n",
       "      <td>0.623625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001226</td>\n",
       "      <td>0.001693</td>\n",
       "      <td>0.001951</td>\n",
       "      <td>0.002337</td>\n",
       "      <td>-0.005181</td>\n",
       "      <td>0.990484</td>\n",
       "      <td>0.991330</td>\n",
       "      <td>0.991808</td>\n",
       "      <td>0.980401</td>\n",
       "      <td>0.819736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138657</td>\n",
       "      <td>0.132265</td>\n",
       "      <td>0.135988</td>\n",
       "      <td>0.216971</td>\n",
       "      <td>0.202100</td>\n",
       "      <td>0.001055</td>\n",
       "      <td>0.001036</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>-0.009762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.981784</td>\n",
       "      <td>0.984609</td>\n",
       "      <td>0.987211</td>\n",
       "      <td>0.984045</td>\n",
       "      <td>0.915812</td>\n",
       "      <td>0.010554</td>\n",
       "      <td>0.011195</td>\n",
       "      <td>0.013696</td>\n",
       "      <td>0.012151</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002390</td>\n",
       "      <td>0.001783</td>\n",
       "      <td>0.003170</td>\n",
       "      <td>0.004121</td>\n",
       "      <td>-0.015429</td>\n",
       "      <td>0.001778</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>0.001898</td>\n",
       "      <td>-0.012886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.150972</td>\n",
       "      <td>0.156217</td>\n",
       "      <td>0.137153</td>\n",
       "      <td>0.199551</td>\n",
       "      <td>0.133011</td>\n",
       "      <td>0.002842</td>\n",
       "      <td>0.002702</td>\n",
       "      <td>0.003065</td>\n",
       "      <td>0.003761</td>\n",
       "      <td>-0.004227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001631</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>0.003439</td>\n",
       "      <td>-0.002182</td>\n",
       "      <td>0.002351</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.002253</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.028651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002397</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.003085</td>\n",
       "      <td>0.002225</td>\n",
       "      <td>0.002802</td>\n",
       "      <td>0.981556</td>\n",
       "      <td>0.988035</td>\n",
       "      <td>0.986810</td>\n",
       "      <td>0.987502</td>\n",
       "      <td>1.049586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.883916</td>\n",
       "      <td>0.870825</td>\n",
       "      <td>0.860023</td>\n",
       "      <td>0.800924</td>\n",
       "      <td>0.699448</td>\n",
       "      <td>0.992135</td>\n",
       "      <td>0.990637</td>\n",
       "      <td>0.988179</td>\n",
       "      <td>0.990448</td>\n",
       "      <td>0.970190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458908</th>\n",
       "      <td>0.990038</td>\n",
       "      <td>0.992553</td>\n",
       "      <td>0.988378</td>\n",
       "      <td>0.988840</td>\n",
       "      <td>1.000397</td>\n",
       "      <td>0.747538</td>\n",
       "      <td>0.766288</td>\n",
       "      <td>0.726014</td>\n",
       "      <td>0.649845</td>\n",
       "      <td>0.639165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160887</td>\n",
       "      <td>0.178610</td>\n",
       "      <td>0.147497</td>\n",
       "      <td>0.115929</td>\n",
       "      <td>0.210982</td>\n",
       "      <td>0.991072</td>\n",
       "      <td>0.991712</td>\n",
       "      <td>0.988248</td>\n",
       "      <td>0.985834</td>\n",
       "      <td>1.018750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458909</th>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.002086</td>\n",
       "      <td>0.003385</td>\n",
       "      <td>0.006687</td>\n",
       "      <td>0.008975</td>\n",
       "      <td>0.015493</td>\n",
       "      <td>0.013397</td>\n",
       "      <td>0.017093</td>\n",
       "      <td>0.007241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.358785</td>\n",
       "      <td>0.449039</td>\n",
       "      <td>0.455791</td>\n",
       "      <td>0.399906</td>\n",
       "      <td>0.408139</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.001358</td>\n",
       "      <td>0.001566</td>\n",
       "      <td>0.001918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458910</th>\n",
       "      <td>0.321152</td>\n",
       "      <td>0.335943</td>\n",
       "      <td>0.280111</td>\n",
       "      <td>0.235822</td>\n",
       "      <td>0.255736</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>-0.006240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010354</td>\n",
       "      <td>0.015805</td>\n",
       "      <td>0.010256</td>\n",
       "      <td>0.018945</td>\n",
       "      <td>-0.008118</td>\n",
       "      <td>0.007314</td>\n",
       "      <td>0.012087</td>\n",
       "      <td>0.010360</td>\n",
       "      <td>0.011841</td>\n",
       "      <td>0.006747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458911</th>\n",
       "      <td>0.009746</td>\n",
       "      <td>0.014462</td>\n",
       "      <td>0.013751</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.890030</td>\n",
       "      <td>0.896242</td>\n",
       "      <td>0.863372</td>\n",
       "      <td>0.873335</td>\n",
       "      <td>0.835714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001696</td>\n",
       "      <td>0.002306</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.002862</td>\n",
       "      <td>0.005366</td>\n",
       "      <td>0.003961</td>\n",
       "      <td>0.006440</td>\n",
       "      <td>0.007306</td>\n",
       "      <td>0.002588</td>\n",
       "      <td>0.019180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458912</th>\n",
       "      <td>0.049477</td>\n",
       "      <td>0.087353</td>\n",
       "      <td>0.062522</td>\n",
       "      <td>0.056077</td>\n",
       "      <td>0.051643</td>\n",
       "      <td>0.670030</td>\n",
       "      <td>0.644919</td>\n",
       "      <td>0.560271</td>\n",
       "      <td>0.617699</td>\n",
       "      <td>0.569747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067850</td>\n",
       "      <td>0.071093</td>\n",
       "      <td>0.046520</td>\n",
       "      <td>0.057233</td>\n",
       "      <td>0.042190</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>0.001821</td>\n",
       "      <td>0.002132</td>\n",
       "      <td>0.003168</td>\n",
       "      <td>-0.007834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>458913 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        2022_pred  2022_pred2  2022_pred3  2022_pred4  2022_pred5  725_pred  \\\n",
       "0        0.001478    0.001888    0.002108    0.002893    0.000823  0.006012   \n",
       "1        0.001226    0.001693    0.001951    0.002337   -0.005181  0.990484   \n",
       "2        0.981784    0.984609    0.987211    0.984045    0.915812  0.010554   \n",
       "3        0.150972    0.156217    0.137153    0.199551    0.133011  0.002842   \n",
       "4        0.002397    0.001636    0.003085    0.002225    0.002802  0.981556   \n",
       "...           ...         ...         ...         ...         ...       ...   \n",
       "458908   0.990038    0.992553    0.988378    0.988840    1.000397  0.747538   \n",
       "458909   0.001042    0.001200    0.002086    0.003385    0.006687  0.008975   \n",
       "458910   0.321152    0.335943    0.280111    0.235822    0.255736  0.000599   \n",
       "458911   0.009746    0.014462    0.013751    0.012191    0.000319  0.890030   \n",
       "458912   0.049477    0.087353    0.062522    0.056077    0.051643  0.670030   \n",
       "\n",
       "        725_pred2  725_pred3  725_pred4  725_pred5  ...  2333_pred  \\\n",
       "0        0.007132   0.010058   0.006341   0.011910  ...   0.001535   \n",
       "1        0.991330   0.991808   0.980401   0.819736  ...   0.138657   \n",
       "2        0.011195   0.013696   0.012151   0.002006  ...   0.002390   \n",
       "3        0.002702   0.003065   0.003761  -0.004227  ...   0.001631   \n",
       "4        0.988035   0.986810   0.987502   1.049586  ...   0.883916   \n",
       "...           ...        ...        ...        ...  ...        ...   \n",
       "458908   0.766288   0.726014   0.649845   0.639165  ...   0.160887   \n",
       "458909   0.015493   0.013397   0.017093   0.007241  ...   0.358785   \n",
       "458910   0.000500   0.000661   0.000738  -0.006240  ...   0.010354   \n",
       "458911   0.896242   0.863372   0.873335   0.835714  ...   0.001696   \n",
       "458912   0.644919   0.560271   0.617699   0.569747  ...   0.067850   \n",
       "\n",
       "        2333_pred2  2333_pred3  2333_pred4  2333_pred5    0_pred   0_pred2  \\\n",
       "0         0.001415    0.002221    0.003336    0.001747  0.730659  0.706918   \n",
       "1         0.132265    0.135988    0.216971    0.202100  0.001055  0.001036   \n",
       "2         0.001783    0.003170    0.004121   -0.015429  0.001778  0.002155   \n",
       "3         0.001939    0.001493    0.003439   -0.002182  0.002351  0.001901   \n",
       "4         0.870825    0.860023    0.800924    0.699448  0.992135  0.990637   \n",
       "...            ...         ...         ...         ...       ...       ...   \n",
       "458908    0.178610    0.147497    0.115929    0.210982  0.991072  0.991712   \n",
       "458909    0.449039    0.455791    0.399906    0.408139  0.000709  0.001066   \n",
       "458910    0.015805    0.010256    0.018945   -0.008118  0.007314  0.012087   \n",
       "458911    0.002306    0.002476    0.002862    0.005366  0.003961  0.006440   \n",
       "458912    0.071093    0.046520    0.057233    0.042190  0.001957  0.001821   \n",
       "\n",
       "         0_pred3   0_pred4   0_pred5  \n",
       "0       0.843714  0.640688  0.623625  \n",
       "1       0.000872  0.001119 -0.009762  \n",
       "2       0.001924  0.001898 -0.012886  \n",
       "3       0.002253  0.001918  0.028651  \n",
       "4       0.988179  0.990448  0.970190  \n",
       "...          ...       ...       ...  \n",
       "458908  0.988248  0.985834  1.018750  \n",
       "458909  0.001358  0.001566  0.001918  \n",
       "458910  0.010360  0.011841  0.006747  \n",
       "458911  0.007306  0.002588  0.019180  \n",
       "458912  0.002132  0.003168 -0.007834  \n",
       "\n",
       "[458913 rows x 30 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newTrainDF                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4427af78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T13:21:24.113041Z",
     "iopub.status.busy": "2022-08-09T13:21:24.112593Z",
     "iopub.status.idle": "2022-08-09T13:21:24.167614Z",
     "shell.execute_reply": "2022-08-09T13:21:24.166454Z"
    },
    "papermill": {
     "duration": 0.068034,
     "end_time": "2022-08-09T13:21:24.170409",
     "exception": false,
     "start_time": "2022-08-09T13:21:24.102375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainY2 = pd.Series(y_)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59931a3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T13:21:24.189923Z",
     "iopub.status.busy": "2022-08-09T13:21:24.189537Z",
     "iopub.status.idle": "2022-08-09T13:23:50.964856Z",
     "shell.execute_reply": "2022-08-09T13:23:50.963721Z"
    },
    "papermill": {
     "duration": 146.787714,
     "end_time": "2022-08-09T13:23:50.967017",
     "exception": false,
     "start_time": "2022-08-09T13:21:24.179303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\tvalid_0's auc: 0.960997\tvalid_0's binary_logloss: 0.37713\n",
      "[20]\tvalid_0's auc: 0.96119\tvalid_0's binary_logloss: 0.346116\n",
      "[30]\tvalid_0's auc: 0.961236\tvalid_0's binary_logloss: 0.289948\n",
      "[40]\tvalid_0's auc: 0.961243\tvalid_0's binary_logloss: 0.301117\n",
      "[50]\tvalid_0's auc: 0.961248\tvalid_0's binary_logloss: 0.295323\n",
      "[60]\tvalid_0's auc: 0.961268\tvalid_0's binary_logloss: 0.289058\n",
      "[70]\tvalid_0's auc: 0.961269\tvalid_0's binary_logloss: 0.262793\n",
      "[80]\tvalid_0's auc: 0.961276\tvalid_0's binary_logloss: 0.254008\n",
      "[90]\tvalid_0's auc: 0.961272\tvalid_0's binary_logloss: 0.243975\n",
      "[100]\tvalid_0's auc: 0.961277\tvalid_0's binary_logloss: 0.24663\n",
      "[110]\tvalid_0's auc: 0.961281\tvalid_0's binary_logloss: 0.243662\n",
      "[120]\tvalid_0's auc: 0.961274\tvalid_0's binary_logloss: 0.23893\n",
      "[130]\tvalid_0's auc: 0.961274\tvalid_0's binary_logloss: 0.234411\n",
      "[140]\tvalid_0's auc: 0.961267\tvalid_0's binary_logloss: 0.229638\n",
      "[150]\tvalid_0's auc: 0.961292\tvalid_0's binary_logloss: 0.228484\n",
      "[160]\tvalid_0's auc: 0.961307\tvalid_0's binary_logloss: 0.231333\n",
      "[170]\tvalid_0's auc: 0.961307\tvalid_0's binary_logloss: 0.228662\n",
      "[180]\tvalid_0's auc: 0.961305\tvalid_0's binary_logloss: 0.22981\n",
      "[190]\tvalid_0's auc: 0.961308\tvalid_0's binary_logloss: 0.227513\n",
      "[200]\tvalid_0's auc: 0.961307\tvalid_0's binary_logloss: 0.228104\n",
      "Top four(71537 total cases) has 66.95314636763375% positives cases being predicted\n",
      "Gini value is 0.9251673974109872\n",
      "Top four(17630 total cases) has 65.82933602625599% positives cases being predicted\n",
      "Gini value is 0.922604353310392\n",
      "LGB - METRICS\n",
      "LGB: Train_score: 0.9626 valid_score: 0.9613\n",
      "LGB: train_vdr score: 0.6833855799373041\n",
      "LGB: valid_vdr score: 0.6801733568964067\n",
      "LGB: Train_score: 0.7973 valid_score: 0.7904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\tvalid_0's auc: 0.960918\tvalid_0's binary_logloss: 0.377014\n",
      "[20]\tvalid_0's auc: 0.960961\tvalid_0's binary_logloss: 0.346002\n",
      "[30]\tvalid_0's auc: 0.961077\tvalid_0's binary_logloss: 0.289872\n",
      "[40]\tvalid_0's auc: 0.961094\tvalid_0's binary_logloss: 0.300979\n",
      "[50]\tvalid_0's auc: 0.961085\tvalid_0's binary_logloss: 0.295165\n",
      "[60]\tvalid_0's auc: 0.961088\tvalid_0's binary_logloss: 0.288896\n",
      "[70]\tvalid_0's auc: 0.96109\tvalid_0's binary_logloss: 0.262698\n",
      "[80]\tvalid_0's auc: 0.961093\tvalid_0's binary_logloss: 0.253929\n",
      "[90]\tvalid_0's auc: 0.961097\tvalid_0's binary_logloss: 0.243935\n",
      "[100]\tvalid_0's auc: 0.961185\tvalid_0's binary_logloss: 0.246568\n",
      "[110]\tvalid_0's auc: 0.961183\tvalid_0's binary_logloss: 0.243621\n",
      "[120]\tvalid_0's auc: 0.961183\tvalid_0's binary_logloss: 0.238922\n",
      "[130]\tvalid_0's auc: 0.961179\tvalid_0's binary_logloss: 0.234446\n",
      "[140]\tvalid_0's auc: 0.961176\tvalid_0's binary_logloss: 0.229742\n",
      "[150]\tvalid_0's auc: 0.961293\tvalid_0's binary_logloss: 0.228571\n",
      "[160]\tvalid_0's auc: 0.961298\tvalid_0's binary_logloss: 0.231343\n",
      "[170]\tvalid_0's auc: 0.961292\tvalid_0's binary_logloss: 0.228708\n",
      "[180]\tvalid_0's auc: 0.96129\tvalid_0's binary_logloss: 0.229814\n",
      "[190]\tvalid_0's auc: 0.961286\tvalid_0's binary_logloss: 0.227566\n",
      "[200]\tvalid_0's auc: 0.961291\tvalid_0's binary_logloss: 0.228119\n",
      "Top four(71518 total cases) has 66.93210746670594% positives cases being predicted\n",
      "Gini value is 0.9251871251794607\n",
      "Top four(17706 total cases) has 66.1659513590844% positives cases being predicted\n",
      "Gini value is 0.9225929556340275\n",
      "LGB - METRICS\n",
      "LGB: Train_score: 0.9626 valid_score: 0.9613\n",
      "LGB: train_vdr score: 0.6832067492794176\n",
      "LGB: valid_vdr score: 0.6810569721450812\n",
      "LGB: Train_score: 0.7973 valid_score: 0.7921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\tvalid_0's auc: 0.962468\tvalid_0's binary_logloss: 0.376019\n",
      "[20]\tvalid_0's auc: 0.962477\tvalid_0's binary_logloss: 0.344805\n",
      "[30]\tvalid_0's auc: 0.962706\tvalid_0's binary_logloss: 0.288117\n",
      "[40]\tvalid_0's auc: 0.962709\tvalid_0's binary_logloss: 0.299469\n",
      "[50]\tvalid_0's auc: 0.962732\tvalid_0's binary_logloss: 0.293604\n",
      "[60]\tvalid_0's auc: 0.962738\tvalid_0's binary_logloss: 0.287256\n",
      "[70]\tvalid_0's auc: 0.962735\tvalid_0's binary_logloss: 0.260681\n",
      "[80]\tvalid_0's auc: 0.962737\tvalid_0's binary_logloss: 0.251797\n",
      "[90]\tvalid_0's auc: 0.962729\tvalid_0's binary_logloss: 0.241618\n",
      "[100]\tvalid_0's auc: 0.962779\tvalid_0's binary_logloss: 0.244364\n",
      "[110]\tvalid_0's auc: 0.9628\tvalid_0's binary_logloss: 0.24136\n",
      "[120]\tvalid_0's auc: 0.962799\tvalid_0's binary_logloss: 0.236547\n",
      "[130]\tvalid_0's auc: 0.9628\tvalid_0's binary_logloss: 0.231939\n",
      "[140]\tvalid_0's auc: 0.962804\tvalid_0's binary_logloss: 0.227048\n",
      "[150]\tvalid_0's auc: 0.962812\tvalid_0's binary_logloss: 0.225864\n",
      "[160]\tvalid_0's auc: 0.962816\tvalid_0's binary_logloss: 0.228812\n",
      "[170]\tvalid_0's auc: 0.96282\tvalid_0's binary_logloss: 0.226055\n",
      "[180]\tvalid_0's auc: 0.962822\tvalid_0's binary_logloss: 0.22725\n",
      "[190]\tvalid_0's auc: 0.962819\tvalid_0's binary_logloss: 0.224892\n",
      "[200]\tvalid_0's auc: 0.962819\tvalid_0's binary_logloss: 0.225507\n",
      "Top four(71327 total cases) has 66.72066651238138% positives cases being predicted\n",
      "Gini value is 0.9243477162556293\n",
      "Top four(17799 total cases) has 66.57409745013886% positives cases being predicted\n",
      "Gini value is 0.9256423994915541\n",
      "LGB - METRICS\n",
      "LGB: Train_score: 0.9622 valid_score: 0.9628\n",
      "LGB: train_vdr score: 0.6827544129094696\n",
      "LGB: valid_vdr score: 0.681351510561306\n",
      "LGB: Train_score: 0.7958 valid_score: 0.7957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\tvalid_0's auc: 0.960908\tvalid_0's binary_logloss: 0.376652\n",
      "[20]\tvalid_0's auc: 0.960929\tvalid_0's binary_logloss: 0.345627\n",
      "[30]\tvalid_0's auc: 0.961273\tvalid_0's binary_logloss: 0.289478\n",
      "[40]\tvalid_0's auc: 0.961275\tvalid_0's binary_logloss: 0.300762\n",
      "[50]\tvalid_0's auc: 0.961281\tvalid_0's binary_logloss: 0.295137\n",
      "[60]\tvalid_0's auc: 0.961283\tvalid_0's binary_logloss: 0.288989\n",
      "[70]\tvalid_0's auc: 0.961288\tvalid_0's binary_logloss: 0.262656\n",
      "[80]\tvalid_0's auc: 0.961291\tvalid_0's binary_logloss: 0.253842\n",
      "[90]\tvalid_0's auc: 0.961288\tvalid_0's binary_logloss: 0.243769\n",
      "[100]\tvalid_0's auc: 0.96129\tvalid_0's binary_logloss: 0.246429\n",
      "[110]\tvalid_0's auc: 0.961289\tvalid_0's binary_logloss: 0.243491\n",
      "[120]\tvalid_0's auc: 0.961295\tvalid_0's binary_logloss: 0.238754\n",
      "[130]\tvalid_0's auc: 0.961331\tvalid_0's binary_logloss: 0.234217\n",
      "[140]\tvalid_0's auc: 0.961348\tvalid_0's binary_logloss: 0.229453\n",
      "[150]\tvalid_0's auc: 0.96135\tvalid_0's binary_logloss: 0.228281\n",
      "[160]\tvalid_0's auc: 0.961349\tvalid_0's binary_logloss: 0.231124\n",
      "[170]\tvalid_0's auc: 0.961359\tvalid_0's binary_logloss: 0.228453\n",
      "[180]\tvalid_0's auc: 0.96136\tvalid_0's binary_logloss: 0.229596\n",
      "[190]\tvalid_0's auc: 0.961424\tvalid_0's binary_logloss: 0.227327\n",
      "[200]\tvalid_0's auc: 0.961429\tvalid_0's binary_logloss: 0.227877\n",
      "Top four(71513 total cases) has 66.92614371522043% positives cases being predicted\n",
      "Gini value is 0.9251391322423743\n",
      "Top four(17719 total cases) has 66.22343782873973% positives cases being predicted\n",
      "Gini value is 0.9228314997090665\n",
      "LGB - METRICS\n",
      "LGB: Train_score: 0.9626 valid_score: 0.9614\n",
      "LGB: train_vdr score: 0.6834415072110074\n",
      "LGB: valid_vdr score: 0.6817588891226594\n",
      "LGB: Train_score: 0.7972 valid_score: 0.7925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\tvalid_0's auc: 0.962099\tvalid_0's binary_logloss: 0.376175\n",
      "[20]\tvalid_0's auc: 0.962126\tvalid_0's binary_logloss: 0.344972\n",
      "[30]\tvalid_0's auc: 0.962384\tvalid_0's binary_logloss: 0.288302\n",
      "[40]\tvalid_0's auc: 0.962391\tvalid_0's binary_logloss: 0.29964\n",
      "[50]\tvalid_0's auc: 0.962393\tvalid_0's binary_logloss: 0.293763\n",
      "[60]\tvalid_0's auc: 0.962391\tvalid_0's binary_logloss: 0.287407\n",
      "[70]\tvalid_0's auc: 0.962389\tvalid_0's binary_logloss: 0.260813\n",
      "[80]\tvalid_0's auc: 0.962395\tvalid_0's binary_logloss: 0.251914\n",
      "[90]\tvalid_0's auc: 0.962402\tvalid_0's binary_logloss: 0.241683\n",
      "[100]\tvalid_0's auc: 0.962401\tvalid_0's binary_logloss: 0.244428\n",
      "[110]\tvalid_0's auc: 0.962399\tvalid_0's binary_logloss: 0.24142\n",
      "[120]\tvalid_0's auc: 0.962398\tvalid_0's binary_logloss: 0.236582\n",
      "[130]\tvalid_0's auc: 0.96244\tvalid_0's binary_logloss: 0.231972\n",
      "[140]\tvalid_0's auc: 0.962503\tvalid_0's binary_logloss: 0.227059\n",
      "[150]\tvalid_0's auc: 0.962508\tvalid_0's binary_logloss: 0.225866\n",
      "[160]\tvalid_0's auc: 0.962512\tvalid_0's binary_logloss: 0.228826\n",
      "[170]\tvalid_0's auc: 0.96251\tvalid_0's binary_logloss: 0.226077\n",
      "[180]\tvalid_0's auc: 0.962507\tvalid_0's binary_logloss: 0.227277\n",
      "[190]\tvalid_0's auc: 0.962529\tvalid_0's binary_logloss: 0.224921\n",
      "[200]\tvalid_0's auc: 0.962527\tvalid_0's binary_logloss: 0.225546\n",
      "Top four(71271 total cases) has 66.65790055016147% positives cases being predicted\n",
      "Gini value is 0.9245409429367487\n",
      "Top four(17829 total cases) has 66.71155059962129% positives cases being predicted\n",
      "Gini value is 0.9250792118585324\n",
      "LGB - METRICS\n",
      "LGB: Train_score: 0.9623 valid_score: 0.9625\n",
      "LGB: train_vdr score: 0.682431650589609\n",
      "LGB: valid_vdr score: 0.6818009678098044\n",
      "LGB: Train_score: 0.7956 valid_score: 0.7961\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits= 5, shuffle=True, random_state=0)\n",
    "models_stage2 = []\n",
    "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(newTrainDF, trainY2)):\n",
    "    train_x, train_y = newTrainDF.iloc[train_idx], trainY2.iloc[train_idx]\n",
    "    valid_x, valid_y = newTrainDF.iloc[valid_idx], trainY2.iloc[valid_idx]\n",
    "    gbm = lgb.LGBMClassifier(\n",
    "        objective='binary', \n",
    "        boosting_type='dart',\n",
    "        num_leaves=30, \n",
    "        learning_rate=0.05,\n",
    "        n_estimators=200,\n",
    "        class_weight = {1:1,0:1},\n",
    "        min_child_samples = 100,\n",
    "        subsample = 0.5,\n",
    "        colsample_bytree = 1,\n",
    "        reg_alpha = 1,\n",
    "        reg_lambda = 1,\n",
    "        # n_jobs = 4,\n",
    "        random_state = 2022  ,\n",
    "        max_bins = 66\n",
    "    )\n",
    "    gbm.fit(train_x, \n",
    "            train_y, \n",
    "            eval_set=[(valid_x, valid_y)], \n",
    "            eval_metric='auc', \n",
    "            early_stopping_rounds=20,\n",
    "            verbose = 10)\n",
    "\n",
    "    models_stage2.append([gbm])\n",
    "    evaluation(gbm,train_x,valid_x,'class')\n",
    "\n",
    "    del train_x, train_y, valid_x, valid_y\n",
    "    gc.collect()  \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c796a79f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T13:23:50.999891Z",
     "iopub.status.busy": "2022-08-09T13:23:50.998853Z",
     "iopub.status.idle": "2022-08-09T13:23:51.190274Z",
     "shell.execute_reply": "2022-08-09T13:23:51.189065Z"
    },
    "papermill": {
     "duration": 0.210867,
     "end_time": "2022-08-09T13:23:51.193014",
     "exception": false,
     "start_time": "2022-08-09T13:23:50.982147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train  \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08664d27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T13:23:51.226880Z",
     "iopub.status.busy": "2022-08-09T13:23:51.226452Z",
     "iopub.status.idle": "2022-08-09T13:24:22.214352Z",
     "shell.execute_reply": "2022-08-09T13:24:22.213232Z"
    },
    "papermill": {
     "duration": 31.008469,
     "end_time": "2022-08-09T13:24:22.217199",
     "exception": false,
     "start_time": "2022-08-09T13:23:51.208730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test1 = pd.read_pickle('../input/amexshycombinedfeatures/test1.pkl')\n",
    "test2 = pd.read_pickle('../input/amexshycombinedfeatures/test2.pkl')\n",
    "test3 = pd.read_pickle('../input/amexshycombinedfeatures/test3.pkl')\n",
    "test4 = pd.read_pickle('../input/amexshycombinedfeatures/test4.pkl')\n",
    "test5 = pd.read_pickle('../input/amexshycombinedfeatures/test5.pkl')\n",
    "test6 = pd.read_pickle('../input/amexshycombinedfeatures/test6.pkl')   \n",
    "test7 = pd.read_pickle('../input/amexshycombinedfeatures/test7.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "354d0d5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T13:24:22.250709Z",
     "iopub.status.busy": "2022-08-09T13:24:22.250327Z",
     "iopub.status.idle": "2022-08-09T13:24:22.419704Z",
     "shell.execute_reply": "2022-08-09T13:24:22.418620Z"
    },
    "papermill": {
     "duration": 0.188957,
     "end_time": "2022-08-09T13:24:22.422072",
     "exception": false,
     "start_time": "2022-08-09T13:24:22.233115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0c04b65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T13:24:22.455085Z",
     "iopub.status.busy": "2022-08-09T13:24:22.454288Z",
     "iopub.status.idle": "2022-08-09T13:24:29.054415Z",
     "shell.execute_reply": "2022-08-09T13:24:29.053200Z"
    },
    "papermill": {
     "duration": 6.619553,
     "end_time": "2022-08-09T13:24:29.057243",
     "exception": false,
     "start_time": "2022-08-09T13:24:22.437690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in test1.columns:\n",
    "    if test1[i].dtypes == 'object':\n",
    "        test1[i]=test1[i].apply(lambda x: hash(str(x))%997)\n",
    "for i in test2.columns:\n",
    "    if test2[i].dtypes == 'object':\n",
    "        test2[i]=test2[i].apply(lambda x: hash(str(x))%997)\n",
    "for i in test3.columns:\n",
    "    if test3[i].dtypes == 'object':\n",
    "        test3[i]=test3[i].apply(lambda x: hash(str(x))%997)\n",
    "for i in test4.columns:\n",
    "    if test4[i].dtypes == 'object':\n",
    "        test4[i]=test4[i].apply(lambda x: hash(str(x))%997)\n",
    "for i in test1.columns:\n",
    "    if test5[i].dtypes == 'object':\n",
    "        test5[i]=test5[i].apply(lambda x: hash(str(x))%997)\n",
    "for i in test6.columns:\n",
    "    if test6[i].dtypes == 'object':\n",
    "        test6[i]=test6[i].apply(lambda x: hash(str(x))%997)\n",
    "for i in test1.columns:\n",
    "    if test7[i].dtypes == 'object':\n",
    "        test7[i]=test7[i].apply(lambda x: hash(str(x))%997)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcd9009a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T13:24:29.094269Z",
     "iopub.status.busy": "2022-08-09T13:24:29.093434Z",
     "iopub.status.idle": "2022-08-09T15:00:50.723111Z",
     "shell.execute_reply": "2022-08-09T15:00:50.721773Z"
    },
    "papermill": {
     "duration": 5781.668505,
     "end_time": "2022-08-09T15:00:50.743633",
     "exception": false,
     "start_time": "2022-08-09T13:24:29.075128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "924621\n",
      "924621\n",
      "924621\n",
      "924621\n",
      "924621\n",
      "924621\n",
      "924621\n",
      "924621\n",
      "924621\n",
      "924621\n",
      "924621\n",
      "924621\n",
      "924621\n",
      "924621\n",
      "924621\n",
      "924621\n",
      "924621\n",
      "924621\n",
      "924621\n",
      "924621\n",
      "924621\n",
      "924621\n",
      "924621\n",
      "924621\n",
      "924621\n",
      "924621\n",
      "924621\n",
      "924621\n",
      "924621\n",
      "924621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame()\n",
    "for idx,model in enumerate(zip(models1,models2,models3)):\n",
    "    array = []\n",
    "    array1 = []\n",
    "    array2 = []\n",
    "    \n",
    "    array+=list(model[0][0].predict_proba(test1)[:,1])\n",
    "    array+=list(model[0][0].predict_proba(test2)[:,1])\n",
    "    array+=list(model[0][0].predict_proba(test3)[:,1])\n",
    "    array+=list(model[0][0].predict_proba(test4)[:,1])\n",
    "    array+=list(model[0][0].predict_proba(test5)[:,1])\n",
    "    array+=list(model[0][0].predict_proba(test6)[:,1])\n",
    "    array+=list(model[0][0].predict_proba(test7)[:,1])\n",
    "    \n",
    "    array1+=list(model[1][0].predict_proba(test1)[:,1])\n",
    "    array1+=list(model[1][0].predict_proba(test2)[:,1])\n",
    "    array1+=list(model[1][0].predict_proba(test3)[:,1])\n",
    "    array1+=list(model[1][0].predict_proba(test4)[:,1])\n",
    "    array1+=list(model[1][0].predict_proba(test5)[:,1])\n",
    "    array1+=list(model[1][0].predict_proba(test6)[:,1])\n",
    "    array1+=list(model[1][0].predict_proba(test7)[:,1])\n",
    "    \n",
    "    array2+=list(model[2][0].predict_proba(test1)[:,1])\n",
    "    array2+=list(model[2][0].predict_proba(test2)[:,1])\n",
    "    array2+=list(model[2][0].predict_proba(test3)[:,1])\n",
    "    array2+=list(model[2][0].predict_proba(test4)[:,1])\n",
    "    array2+=list(model[2][0].predict_proba(test5)[:,1])\n",
    "    array2+=list(model[2][0].predict_proba(test6)[:,1])\n",
    "    array2+=list(model[2][0].predict_proba(test7)[:,1])\n",
    "          \n",
    "    gc.collect()   \n",
    "    print(len(array))    \n",
    "    \n",
    "#     result.append(np.mean(np.array([array,array1]),axis=0))\n",
    "    result[f'm0_{idx}'] = array\n",
    "    result[f'm1_{idx}'] = array1\n",
    "    result[f'm2_{idx}'] = array2\n",
    "\n",
    "test1 = test1.replace([np.inf,-np.inf],0)\n",
    "test1.fillna(0,inplace=True)\n",
    "test2 = test2.replace([np.inf,-np.inf],0)\n",
    "test2.fillna(0,inplace=True)\n",
    "test3 = test3.replace([np.inf,-np.inf],0)\n",
    "test3.fillna(0,inplace=True)\n",
    "test4 = test4.replace([np.inf,-np.inf],0)\n",
    "test4.fillna(0,inplace=True)\n",
    "test5 = test5.replace([np.inf,-np.inf],0)\n",
    "test5.fillna(0,inplace=True)\n",
    "test6 = test6.replace([np.inf,-np.inf],0)\n",
    "test6.fillna(0,inplace=True)\n",
    "test7 = test7.replace([np.inf,-np.inf],0)\n",
    "test7.fillna(0,inplace=True)\n",
    "\n",
    "for idx,model in enumerate(zip(models4,models5)):\n",
    "    array = []\n",
    "    array2 = []\n",
    "    \n",
    "    array+=list(model[0][0].predict_proba(test1)[:,1])\n",
    "    array+=list(model[0][0].predict_proba(test2)[:,1])\n",
    "    array+=list(model[0][0].predict_proba(test3)[:,1])\n",
    "    array+=list(model[0][0].predict_proba(test4)[:,1])\n",
    "    array+=list(model[0][0].predict_proba(test5)[:,1])\n",
    "    array+=list(model[0][0].predict_proba(test6)[:,1])\n",
    "    array+=list(model[0][0].predict_proba(test7)[:,1])\n",
    "    \n",
    "        \n",
    "    array2+=list(model[1][0].predict(test1))\n",
    "    array2+=list(model[1][0].predict(test2))\n",
    "    array2+=list(model[1][0].predict(test3))\n",
    "    array2+=list(model[1][0].predict(test4))\n",
    "    array2+=list(model[1][0].predict(test5))\n",
    "    array2+=list(model[1][0].predict(test6))\n",
    "    array2+=list(model[1][0].predict(test7))\n",
    "    \n",
    "    result[f'm3_{idx}'] = array\n",
    "    result[f'm4_{idx}'] = array2\n",
    "\n",
    "\n",
    "result.head()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8f24b0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T15:00:50.782290Z",
     "iopub.status.busy": "2022-08-09T15:00:50.781856Z",
     "iopub.status.idle": "2022-08-09T15:00:51.023241Z",
     "shell.execute_reply": "2022-08-09T15:00:51.022286Z"
    },
    "papermill": {
     "duration": 0.264199,
     "end_time": "2022-08-09T15:00:51.025723",
     "exception": false,
     "start_time": "2022-08-09T15:00:50.761524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for idx,i in enumerate(modelNum):   \n",
    "    for j in [0,1,2,3,4]:   \n",
    "        result[f'{i}_pred{j}'] = (result[f'm{j}_{0*idx}'] + result[f'm{j}_{0*idx+1}'] + result[f'm{j}_{0*idx+2}'] + result[f'm{j}_{0*idx+3}'] + result[f'm{j}_{0*idx+4}'])/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fabeb24d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T15:00:51.063648Z",
     "iopub.status.busy": "2022-08-09T15:00:51.063260Z",
     "iopub.status.idle": "2022-08-09T15:00:51.408517Z",
     "shell.execute_reply": "2022-08-09T15:00:51.407429Z"
    },
    "papermill": {
     "duration": 0.366969,
     "end_time": "2022-08-09T15:00:51.410906",
     "exception": false,
     "start_time": "2022-08-09T15:00:51.043937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2022_pred0</th>\n",
       "      <th>2022_pred1</th>\n",
       "      <th>2022_pred2</th>\n",
       "      <th>2022_pred3</th>\n",
       "      <th>2022_pred4</th>\n",
       "      <th>725_pred0</th>\n",
       "      <th>725_pred1</th>\n",
       "      <th>725_pred2</th>\n",
       "      <th>725_pred3</th>\n",
       "      <th>725_pred4</th>\n",
       "      <th>...</th>\n",
       "      <th>2333_pred0</th>\n",
       "      <th>2333_pred1</th>\n",
       "      <th>2333_pred2</th>\n",
       "      <th>2333_pred3</th>\n",
       "      <th>2333_pred4</th>\n",
       "      <th>0_pred0</th>\n",
       "      <th>0_pred1</th>\n",
       "      <th>0_pred2</th>\n",
       "      <th>0_pred3</th>\n",
       "      <th>0_pred4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.020918</td>\n",
       "      <td>0.019251</td>\n",
       "      <td>0.019321</td>\n",
       "      <td>0.039884</td>\n",
       "      <td>0.002046</td>\n",
       "      <td>0.020918</td>\n",
       "      <td>0.019251</td>\n",
       "      <td>0.019321</td>\n",
       "      <td>0.039884</td>\n",
       "      <td>0.002046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020918</td>\n",
       "      <td>0.019251</td>\n",
       "      <td>0.019321</td>\n",
       "      <td>0.039884</td>\n",
       "      <td>0.002046</td>\n",
       "      <td>0.020918</td>\n",
       "      <td>0.019251</td>\n",
       "      <td>0.019321</td>\n",
       "      <td>0.039884</td>\n",
       "      <td>0.002046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000961</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>0.003429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.048897</td>\n",
       "      <td>0.050228</td>\n",
       "      <td>0.032307</td>\n",
       "      <td>0.036536</td>\n",
       "      <td>0.064407</td>\n",
       "      <td>0.048897</td>\n",
       "      <td>0.050228</td>\n",
       "      <td>0.032307</td>\n",
       "      <td>0.036536</td>\n",
       "      <td>0.064407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048897</td>\n",
       "      <td>0.050228</td>\n",
       "      <td>0.032307</td>\n",
       "      <td>0.036536</td>\n",
       "      <td>0.064407</td>\n",
       "      <td>0.048897</td>\n",
       "      <td>0.050228</td>\n",
       "      <td>0.032307</td>\n",
       "      <td>0.036536</td>\n",
       "      <td>0.064407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.202765</td>\n",
       "      <td>0.198628</td>\n",
       "      <td>0.179081</td>\n",
       "      <td>0.353863</td>\n",
       "      <td>0.275618</td>\n",
       "      <td>0.202765</td>\n",
       "      <td>0.198628</td>\n",
       "      <td>0.179081</td>\n",
       "      <td>0.353863</td>\n",
       "      <td>0.275618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202765</td>\n",
       "      <td>0.198628</td>\n",
       "      <td>0.179081</td>\n",
       "      <td>0.353863</td>\n",
       "      <td>0.275618</td>\n",
       "      <td>0.202765</td>\n",
       "      <td>0.198628</td>\n",
       "      <td>0.179081</td>\n",
       "      <td>0.353863</td>\n",
       "      <td>0.275618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.843242</td>\n",
       "      <td>0.838195</td>\n",
       "      <td>0.806058</td>\n",
       "      <td>0.815899</td>\n",
       "      <td>0.747304</td>\n",
       "      <td>0.843242</td>\n",
       "      <td>0.838195</td>\n",
       "      <td>0.806058</td>\n",
       "      <td>0.815899</td>\n",
       "      <td>0.747304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.843242</td>\n",
       "      <td>0.838195</td>\n",
       "      <td>0.806058</td>\n",
       "      <td>0.815899</td>\n",
       "      <td>0.747304</td>\n",
       "      <td>0.843242</td>\n",
       "      <td>0.838195</td>\n",
       "      <td>0.806058</td>\n",
       "      <td>0.815899</td>\n",
       "      <td>0.747304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924616</th>\n",
       "      <td>0.017123</td>\n",
       "      <td>0.019227</td>\n",
       "      <td>0.016621</td>\n",
       "      <td>0.021246</td>\n",
       "      <td>0.019349</td>\n",
       "      <td>0.017123</td>\n",
       "      <td>0.019227</td>\n",
       "      <td>0.016621</td>\n",
       "      <td>0.021246</td>\n",
       "      <td>0.019349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017123</td>\n",
       "      <td>0.019227</td>\n",
       "      <td>0.016621</td>\n",
       "      <td>0.021246</td>\n",
       "      <td>0.019349</td>\n",
       "      <td>0.017123</td>\n",
       "      <td>0.019227</td>\n",
       "      <td>0.016621</td>\n",
       "      <td>0.021246</td>\n",
       "      <td>0.019349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924617</th>\n",
       "      <td>0.797747</td>\n",
       "      <td>0.818262</td>\n",
       "      <td>0.802072</td>\n",
       "      <td>0.796201</td>\n",
       "      <td>0.721303</td>\n",
       "      <td>0.797747</td>\n",
       "      <td>0.818262</td>\n",
       "      <td>0.802072</td>\n",
       "      <td>0.796201</td>\n",
       "      <td>0.721303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.797747</td>\n",
       "      <td>0.818262</td>\n",
       "      <td>0.802072</td>\n",
       "      <td>0.796201</td>\n",
       "      <td>0.721303</td>\n",
       "      <td>0.797747</td>\n",
       "      <td>0.818262</td>\n",
       "      <td>0.802072</td>\n",
       "      <td>0.796201</td>\n",
       "      <td>0.721303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924618</th>\n",
       "      <td>0.399833</td>\n",
       "      <td>0.381369</td>\n",
       "      <td>0.400880</td>\n",
       "      <td>0.511784</td>\n",
       "      <td>0.525730</td>\n",
       "      <td>0.399833</td>\n",
       "      <td>0.381369</td>\n",
       "      <td>0.400880</td>\n",
       "      <td>0.511784</td>\n",
       "      <td>0.525730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.399833</td>\n",
       "      <td>0.381369</td>\n",
       "      <td>0.400880</td>\n",
       "      <td>0.511784</td>\n",
       "      <td>0.525730</td>\n",
       "      <td>0.399833</td>\n",
       "      <td>0.381369</td>\n",
       "      <td>0.400880</td>\n",
       "      <td>0.511784</td>\n",
       "      <td>0.525730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924619</th>\n",
       "      <td>0.276957</td>\n",
       "      <td>0.280984</td>\n",
       "      <td>0.311625</td>\n",
       "      <td>0.295410</td>\n",
       "      <td>0.289080</td>\n",
       "      <td>0.276957</td>\n",
       "      <td>0.280984</td>\n",
       "      <td>0.311625</td>\n",
       "      <td>0.295410</td>\n",
       "      <td>0.289080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.276957</td>\n",
       "      <td>0.280984</td>\n",
       "      <td>0.311625</td>\n",
       "      <td>0.295410</td>\n",
       "      <td>0.289080</td>\n",
       "      <td>0.276957</td>\n",
       "      <td>0.280984</td>\n",
       "      <td>0.311625</td>\n",
       "      <td>0.295410</td>\n",
       "      <td>0.289080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924620</th>\n",
       "      <td>0.048446</td>\n",
       "      <td>0.043334</td>\n",
       "      <td>0.047160</td>\n",
       "      <td>0.060836</td>\n",
       "      <td>0.060635</td>\n",
       "      <td>0.048446</td>\n",
       "      <td>0.043334</td>\n",
       "      <td>0.047160</td>\n",
       "      <td>0.060836</td>\n",
       "      <td>0.060635</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048446</td>\n",
       "      <td>0.043334</td>\n",
       "      <td>0.047160</td>\n",
       "      <td>0.060836</td>\n",
       "      <td>0.060635</td>\n",
       "      <td>0.048446</td>\n",
       "      <td>0.043334</td>\n",
       "      <td>0.047160</td>\n",
       "      <td>0.060836</td>\n",
       "      <td>0.060635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>924621 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        2022_pred0  2022_pred1  2022_pred2  2022_pred3  2022_pred4  725_pred0  \\\n",
       "0         0.020918    0.019251    0.019321    0.039884    0.002046   0.020918   \n",
       "1         0.000961    0.001143    0.000968    0.001796    0.003429   0.000961   \n",
       "2         0.048897    0.050228    0.032307    0.036536    0.064407   0.048897   \n",
       "3         0.202765    0.198628    0.179081    0.353863    0.275618   0.202765   \n",
       "4         0.843242    0.838195    0.806058    0.815899    0.747304   0.843242   \n",
       "...            ...         ...         ...         ...         ...        ...   \n",
       "924616    0.017123    0.019227    0.016621    0.021246    0.019349   0.017123   \n",
       "924617    0.797747    0.818262    0.802072    0.796201    0.721303   0.797747   \n",
       "924618    0.399833    0.381369    0.400880    0.511784    0.525730   0.399833   \n",
       "924619    0.276957    0.280984    0.311625    0.295410    0.289080   0.276957   \n",
       "924620    0.048446    0.043334    0.047160    0.060836    0.060635   0.048446   \n",
       "\n",
       "        725_pred1  725_pred2  725_pred3  725_pred4  ...  2333_pred0  \\\n",
       "0        0.019251   0.019321   0.039884   0.002046  ...    0.020918   \n",
       "1        0.001143   0.000968   0.001796   0.003429  ...    0.000961   \n",
       "2        0.050228   0.032307   0.036536   0.064407  ...    0.048897   \n",
       "3        0.198628   0.179081   0.353863   0.275618  ...    0.202765   \n",
       "4        0.838195   0.806058   0.815899   0.747304  ...    0.843242   \n",
       "...           ...        ...        ...        ...  ...         ...   \n",
       "924616   0.019227   0.016621   0.021246   0.019349  ...    0.017123   \n",
       "924617   0.818262   0.802072   0.796201   0.721303  ...    0.797747   \n",
       "924618   0.381369   0.400880   0.511784   0.525730  ...    0.399833   \n",
       "924619   0.280984   0.311625   0.295410   0.289080  ...    0.276957   \n",
       "924620   0.043334   0.047160   0.060836   0.060635  ...    0.048446   \n",
       "\n",
       "        2333_pred1  2333_pred2  2333_pred3  2333_pred4   0_pred0   0_pred1  \\\n",
       "0         0.019251    0.019321    0.039884    0.002046  0.020918  0.019251   \n",
       "1         0.001143    0.000968    0.001796    0.003429  0.000961  0.001143   \n",
       "2         0.050228    0.032307    0.036536    0.064407  0.048897  0.050228   \n",
       "3         0.198628    0.179081    0.353863    0.275618  0.202765  0.198628   \n",
       "4         0.838195    0.806058    0.815899    0.747304  0.843242  0.838195   \n",
       "...            ...         ...         ...         ...       ...       ...   \n",
       "924616    0.019227    0.016621    0.021246    0.019349  0.017123  0.019227   \n",
       "924617    0.818262    0.802072    0.796201    0.721303  0.797747  0.818262   \n",
       "924618    0.381369    0.400880    0.511784    0.525730  0.399833  0.381369   \n",
       "924619    0.280984    0.311625    0.295410    0.289080  0.276957  0.280984   \n",
       "924620    0.043334    0.047160    0.060836    0.060635  0.048446  0.043334   \n",
       "\n",
       "         0_pred2   0_pred3   0_pred4  \n",
       "0       0.019321  0.039884  0.002046  \n",
       "1       0.000968  0.001796  0.003429  \n",
       "2       0.032307  0.036536  0.064407  \n",
       "3       0.179081  0.353863  0.275618  \n",
       "4       0.806058  0.815899  0.747304  \n",
       "...          ...       ...       ...  \n",
       "924616  0.016621  0.021246  0.019349  \n",
       "924617  0.802072  0.796201  0.721303  \n",
       "924618  0.400880  0.511784  0.525730  \n",
       "924619  0.311625  0.295410  0.289080  \n",
       "924620  0.047160  0.060836  0.060635  \n",
       "\n",
       "[924621 rows x 30 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = result.iloc[:,-30:]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29f19453",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T15:00:51.449308Z",
     "iopub.status.busy": "2022-08-09T15:00:51.448629Z",
     "iopub.status.idle": "2022-08-09T15:01:08.697141Z",
     "shell.execute_reply": "2022-08-09T15:01:08.696206Z"
    },
    "papermill": {
     "duration": 17.270599,
     "end_time": "2022-08-09T15:01:08.699843",
     "exception": false,
     "start_time": "2022-08-09T15:00:51.429244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for i in models_stage2:\n",
    "    predictions.append(list(i[0].predict_proba(result)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06f5ae6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T15:01:08.738607Z",
     "iopub.status.busy": "2022-08-09T15:01:08.737809Z",
     "iopub.status.idle": "2022-08-09T15:01:09.000492Z",
     "shell.execute_reply": "2022-08-09T15:01:08.999344Z"
    },
    "papermill": {
     "duration": 0.284591,
     "end_time": "2022-08-09T15:01:09.002677",
     "exception": false,
     "start_time": "2022-08-09T15:01:08.718086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.046012\n",
       "1         0.021355\n",
       "2         0.078031\n",
       "3         0.258599\n",
       "4         0.775241\n",
       "            ...   \n",
       "924616    0.040804\n",
       "924617    0.748197\n",
       "924618    0.401789\n",
       "924619    0.322673\n",
       "924620    0.081115\n",
       "Name: combined, Length: 924621, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['combined'] = np.mean(predictions,axis=0)\n",
    "result['combined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de6a1284",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T15:01:09.041550Z",
     "iopub.status.busy": "2022-08-09T15:01:09.040894Z",
     "iopub.status.idle": "2022-08-09T15:01:13.174498Z",
     "shell.execute_reply": "2022-08-09T15:01:13.173336Z"
    },
    "papermill": {
     "duration": 4.156416,
     "end_time": "2022-08-09T15:01:13.177317",
     "exception": false,
     "start_time": "2022-08-09T15:01:09.020901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ids = pd.read_pickle('../input/amexlgbselectedfeatures/ids.pkl')\n",
    "submission = pd.DataFrame({'customer_ID':ids,'prediction':result['combined']})\n",
    "submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac8a4a71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T15:01:13.216785Z",
     "iopub.status.busy": "2022-08-09T15:01:13.215789Z",
     "iopub.status.idle": "2022-08-09T15:01:17.350062Z",
     "shell.execute_reply": "2022-08-09T15:01:17.349102Z"
    },
    "papermill": {
     "duration": 4.15618,
     "end_time": "2022-08-09T15:01:17.352303",
     "exception": false,
     "start_time": "2022-08-09T15:01:13.196123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    924621.000000\n",
      "mean          0.257861\n",
      "std           0.323084\n",
      "min           0.021355\n",
      "25%           0.021431\n",
      "50%           0.057144\n",
      "75%           0.471344\n",
      "max           0.971813\n",
      "Name: prediction, dtype: float64\n",
      "38361\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_submission(df):\n",
    "    sns.distplot(df['prediction'])\n",
    "    print(df['prediction'].describe())\n",
    "    print(len(df[df['prediction']>0.95]))\n",
    "    plt.show()   \n",
    "\n",
    "plot_submission(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24dcd8b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T15:01:17.392858Z",
     "iopub.status.busy": "2022-08-09T15:01:17.391894Z",
     "iopub.status.idle": "2022-08-09T15:01:17.396456Z",
     "shell.execute_reply": "2022-08-09T15:01:17.395428Z"
    },
    "papermill": {
     "duration": 0.027198,
     "end_time": "2022-08-09T15:01:17.398652",
     "exception": false,
     "start_time": "2022-08-09T15:01:17.371454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# submission['prediction'] *= .99\n",
    "# submission.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6908.116789,
   "end_time": "2022-08-09T15:01:19.262153",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-08-09T13:06:11.145364",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
